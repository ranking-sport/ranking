{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c2a8e80-7d29-432f-bc6e-34a92681b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "# --- paths & device ---\n",
    "LLAMA_MODEL_PATH = \"/scratch/nitishk_iitp/Model/Ranking-3B/epoch_5\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eda74f3d-bfea-4508-ac33-ddd955a8ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e48ec8be-d36b-43c1-b592-ae07a8796f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLAMA_MODEL_PATH, padding_side=\"left\", local_files_only=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# --- config ---\n",
    "config = AutoConfig.from_pretrained(LLAMA_MODEL_PATH, local_files_only=True)\n",
    "config.rope_scaling = {\"type\": \"dynamic\", \"factor\": 8.0}   # keep if you trained with dynamic RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46197a8a-6034-41a9-88f1-cca1058ed63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2feaef3180e4530ace4e5cfaf2d8436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /scratch/nitishk_iitp/Model/Ranking-3B/epoch_5 were not used when initializing LlamaForCausalLM: ['v_head.summary.bias', 'v_head.summary.weight']\n",
      "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# --- model ---\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    LLAMA_MODEL_PATH,\n",
    "    config=config,\n",
    "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\",           # loads on multiple GPUs if available\n",
    "    local_files_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ce6d8be-a8bf-44cd-a2b7-d602930d0ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "718f53ae-4051-4ba3-9f93-1c12715ed133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- generation helper ---\n",
    "def generate(prompts, max_new_tokens=128, temperature=0.7, top_p=0.9):\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "        )\n",
    "    return tokenizer.batch_decode(out, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f7be9ae-fcd2-4521-b7fc-3adb5b5cbe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain PPO in one sentence. Please. Please,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "# quick sanity test\n",
    "if __name__ == \"__main__\":\n",
    "    print(generate(\"Explain PPO in one sentence.\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f964cff5-18be-4e51-be52-04c672ad381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data points ===\n",
    "data_points = [\n",
    "    {\"candidates\": [\"Eoin Morgan commented on England's underperformance, suggesting something is unsettled within the team.\", \"Chris Woakes expressed disappointment and mentioned the lack of confidence in the team.\", \"Jos Buttler acknowledged the team's poor performance and the need to play for Champions Trophy qualification.\", \"Jasprit Bumrah mentioned the team's enjoyment of the tournament and their practice in evening conditions.\", \"Rohit Sharma, adjudged the player of the match, emphasized the importance of his partnership with KL Rahul and taking the game deep.\", \"Rohit Sharma felt India were 30-40 runs short but was pleased with the overall performance.\", \"India's victory will galvanize the team as they head into the business end of the tournament.\", \"England's captain Jos Buttler will have much to contemplate as their chances of progression look even more scant.\", \"Rohit Sharma was named Player of the Match for his 87 runs.\", \"India earned 2 points from the match.\", \"Rohit Sharma expressed pride in the team's character and experience, noting the challenge of batting first and the effectiveness of their bowling attack.\", \"Jos Buttler expressed disappointment in England's performance, particularly their batting, despite a good start by the bowlers.\", \"India captain Rohit Sharma: 'This was a game that showed a lot of character in our squad. When times were tough, our experienced players stood up at the right time and fought for us.'\", \"England captain Jos Buttler: 'Very disappointing. At the halfway stage chasing 230 we fancied ourselves. But it's the same old story.'\", \"Player of the match Rohit Sharma: 'Looking at where we were after the first 10 overs of our batting, it was important to put on a partnership like myself and KL Rahul did. It was a challenging pitch to start with but it got easier the longer you spent in the middle. We are very happy with the performance.'\"], \"ranking\": [12, 11, 10, 15, 8, 9, 5, 6, 14, 13, 4, 3, 2, 1, 7]},\n",
    "{\"candidates\": [\"India maintained their 100% record at the Cricket World Cup.\", \"England's World Cup defense is in a dire state, needing to win all remaining games and hoping for other results to go their way.\", \"The stadium was emptying behind the commentators as the match concluded.\", \"India are not mathematically into the semi-finals, nor are England mathematically out of the tournament.\", \"India remain the sole undefeated team in the tournament with this win.\", \"India displaced South Africa at the top of the standings with 12 points in six matches.\", \"England's next match is against Australia on November 4, which is a must-win for them.\", \"England's bowlers and fielders showed commitment and quality, with Chris Woakes delivering a seven-over opening spell that went for just 23 runs.\", \"Virat Kohli was dismissed for a nine-ball duck by David Willey.\", \"Rohit Sharma scored 87 runs off 101 balls, stabilizing India's innings.\", \"The match was held at Bharat Ratna Shri Atal Bihari Vajpayee Ekana Cricket Stadium, Lucknow.\", \"The match was part of the ICC Cricket World Cup 2023.\", \"India stay unbeaten with six wins in as many games and regain the top spot.\", \"England remain at the bottom of the points table with their fifth defeat in six games.\", \"India's pacers Jasprit Bumrah and Mohammed Shami ripped through the England top-order in Lucknow.\", \"India's win leaves England rooted to the bottom of the standings.\", \"India's unchanged team took off at the back of Rohit Sharma's aggressive charge.\", \"England's spin-bowling all-rounders tried to rebuild but were undone by India's bowlers.\", \"England's last four innings have ended in scores of 215, 170, 156 and 129. Against Sri Lanka, they went from 45-0 to 156 all out. Today, it is 30-0 to 129.\"], \"ranking\": [5, 2, 18, 15, 1, 4, 12, 8, 11, 3, 19, 16, 6, 14, 7, 9, 10, 13, 17]},\n",
    "{\"candidates\": [\"Sherfane Rutherford scored 80 runs off 82 balls with 7 fours and 4 sixes.\", \"Wanindu Hasaranga took 4 wickets for 40 runs in 8 overs.\", \"Maheesh Theekshana was named Player of the Match.\", \"Sri Lanka beat West Indies by 5 wickets.\", \"Charith Asalanka scored an unbeaten 62 off 61 balls.\", \"Sri Lanka win by 5 wickets\", \"Roston Chase to Kamindu Mendis. Off break length ball, outside off stump on the back foot driving, well timed to deep backward point for 2 runs, fielded by Carty.\", \"Roston Chase to Charith Asalanka. Off break half volley, outside off stump on the front foot driving, well timed to deep cover for 1 run, fielded by Carty.\", \"Alick Athanaze to Kamindu Mendis. Off break length ball, outside off stump on the front foot defending, to short extra cover for no runs.\", \"Alick Athanaze to Kamindu Mendis. Off break length ball, outside off stump on the front foot pushing, to short extra cover for no runs, fielded by Walsh.\", \"Alick Athanaze to Charith Asalanka. Off break half volley, outside off stump on the front foot driving, to long off for 1 run, fielded by Rutherford.\", \"FOUR! Alick Athanaze to Charith Asalanka. Off break length ball, outside off stump on the back foot pulling, well timed in the air under control past deep mid wicket for 4 runs.\", \"Alick Athanaze to Kamindu Mendis. Off break back of a length, outside off stump on the back foot pulling, mis-timed in the air uncontrolled to deep mid wicket for 1 run, fielded by Carty.\", \"Alick Athanaze to Kamindu Mendis. Off break half volley, outside off stump on the front foot driving, to extra cover for no runs, fielded by Walsh.\", \"Roston Chase to Kamindu Mendis. Off break length ball, outside off stump on the back foot cutting, well timed to deep cover for 1 run, fielded by Carty.\"], \"ranking\": [5, 4, 3, 2, 6, 1, 8, 9, 11, 10, 7, 12, 13, 14, 15]},\n",
    "{\"candidates\": [\"The New York Knicks will take on the Milwaukee Bucks in NBA action at Madison Square Garden on Saturday, starting at 11:30am AEDT.\", \"Led by star players Jalen Brunson, Karl-Anthony Towns and Mikal Bridges, the Knicks are aiming to beat a Bucks team that includes Giannis Antetokounmpo, Damian Lillard and Bobby Portis.\", \"Stats Insider's predictive analytics model currently gives the Knicks a 68% chance of beating the Bucks at Madison Square Garden.\", \"The Knicks are listed as 6.5-point favourites against the Bucks, with odds of $1.91 available at Bet365.\", \"According to Stats Insider's model, the Bucks (+6.5) are predicted to cover the line 54% of the time, while the 223.5-point over/under is expected to go over 51% of the time.\", \"Stats Insider's predicted final score for Knicks vs Bucks at Madison Square Garden on Saturday is the Knicks winning 114-109.\", \"Jalen Brunson is expected to lead the Knicks with 36 points, 4 rebounds and 8 assists, while Giannis Antetokounmpo is projected to finish with 31 points, 11 rebounds and 9 assists for the Bucks.\", \"Milwaukee Bucks are looking to break their four-game road losing streak when they face the New York Knicks.\", \"The Knicks are favored to win with a -7.5 point spread according to BETMGM Sportsbook.\", \"The over/under for the game is set at 225.5 points.\", \"New York Knicks had a strong previous season with a 50-32 overall record and 35-17 in Eastern Conference games.\", \"Milwaukee Bucks finished the previous season with a 49-33 overall record and 34-18 in Eastern Conference action.\", \"Key injuries for the Knicks include Cameron Payne (day to day with a hamstring injury), Precious Achiuwa (out with a hamstring injury), and Mitchell Robinson (out with an ankle injury).\", \"Key injuries for the Bucks include Khris Middleton (out with an ankle injury) and Giannis Antetokounmpo (day to day with an adductor injury).\"], \"ranking\": [12, 5, 8, 10, 9, 4, 3, 2, 11, 7, 6, 1, 13, 14]},\n",
    "{\"candidates\": [\"Memphis Grizzlies secured a 124-111 victory over Orlando Magic.\", \"Yuki Kawamura made his appearance in the last two minutes of the game but missed both 3-point attempts and had a turnover.\", \"Ja Morant played 25 minutes despite being listed as questionable with right thigh soreness.\", \"Morant scored 16 points and made 10 assists in the game.\", \"Ja Morant was twisting in the air and catching alley-oops.\", \"Memphis was blocking balls and intercepting passes.\", \"Jay Huff threw down multiple reverse dunks.\", \"The Grizzlies finished with 38 assists, their most since April 2023.\", \"Five players were tied with a team-high 11 points at the end of the third quarter.\", \"Jaren Jackson Jr. returned from a hamstring injury and finished with 13 points and four rebounds.\", \"Santi Aldama scored 22 points, leading the team in scoring for the second time in three games.\", \"Scotty Pippen Jr. finished with 11 points and 12 assists.\", \"Ja Morant finished with a double-double, scoring 16 points with 10 assists.\", \"Morant's energy was infectious in the Grizzlies' 124-111 home-opening win over the Orlando Magic.\", \"Jay Huff and Scotty Pippen Jr. had career nights thanks to Morant's involvement.\"], \"ranking\": [5, 12, 9, 8, 11, 10, 7, 4, 14, 6, 3, 2, 1, 13, 15]},\n",
    "{\n",
    "    \"candidates\": [\n",
    "        \"Virat Kohli scored a match-winning 97 under pressure.\",\n",
    "        \"Steve Smith top-scored for Australia with 85 runs.\",\n",
    "        \"India chased down 265 with four wickets remaining.\",\n",
    "        \"Rohit Sharma contributed a quick 45 at the top.\",\n",
    "        \"Pat Cummins took three wickets but was expensive.\",\n",
    "        \"Australia collapsed in the middle overs, losing 4 wickets for 20 runs.\",\n",
    "        \"Jasprit Bumrah bowled an excellent death over.\",\n",
    "        \"Hardik Pandya's cameo of 28 from 12 turned the game.\",\n",
    "        \"KL Rahul anchored the chase with a composed 50.\",\n",
    "        \"India moved to the top of the table with the win.\",\n",
    "        \"The match was played at Eden Gardens, Kolkata.\",\n",
    "        \"Australia have now lost 3 matches in the tournament.\"\n",
    "    ],\n",
    "    \"ranking\": [2, 5, 1, 6, 10, 4, 3, 7, 8, 9, 12, 11]\n",
    "},\n",
    "\n",
    "{\n",
    "    \"candidates\": [\n",
    "        \"Real Madrid secured a 2-1 comeback win over Bayern Munich.\",\n",
    "        \"Karim Benzema scored both goals for Real Madrid.\",\n",
    "        \"Manuel Neuer made 7 crucial saves for Bayern.\",\n",
    "        \"The match saw a red card for Bayern defender Upamecano.\",\n",
    "        \"Luka Modric controlled the midfield brilliantly.\",\n",
    "        \"Vinicius Jr. won the penalty that led to the equalizer.\",\n",
    "        \"Joshua Kimmich's goal gave Bayern an early lead.\",\n",
    "        \"Toni Kroos was subbed off in the 70th minute.\",\n",
    "        \"The game was played at Santiago Bernabéu.\",\n",
    "        \"Real Madrid now qualify for the final.\",\n",
    "        \"Bayern had 56% possession but lacked finishing.\"\n",
    "    ],\n",
    "    \"ranking\": [1, 2, 6, 7, 4, 3, 5, 10, 11, 8, 9]\n",
    "},\n",
    "\n",
    "{\n",
    "    \"candidates\": [\n",
    "        \"LeBron James posted 30 points, 12 rebounds, and 8 assists.\",\n",
    "        \"Anthony Davis added 25 points and 15 boards.\",\n",
    "        \"The Lakers beat the Warriors 118-110 in Game 5.\",\n",
    "        \"Stephen Curry had a quiet night with 22 points.\",\n",
    "        \"Draymond Green fouled out in the fourth quarter.\",\n",
    "        \"Austin Reaves scored 18 off the bench.\",\n",
    "        \"The Lakers now lead the series 3-2.\",\n",
    "        \"Klay Thompson was held to 5/17 shooting.\",\n",
    "        \"Golden State shot just 29% from three-point range.\",\n",
    "        \"Darvin Ham praised the team's defensive effort.\",\n",
    "        \"The crowd at Crypto.com Arena was electric.\"\n",
    "    ],\n",
    "    \"ranking\": [1, 3, 2, 6, 8, 5, 4, 7, 9, 10, 11]\n",
    "},\n",
    "\n",
    "{\n",
    "    \"candidates\": [\n",
    "        \"Pakistan defended 220 successfully in a low-scoring thriller.\",\n",
    "        \"Shaheen Afridi took 4 wickets for just 22 runs.\",\n",
    "        \"Shadab Khan's late strikes turned the game.\",\n",
    "        \"Quinton de Kock scored 70 but lacked support.\",\n",
    "        \"South Africa lost 5 wickets in the final 6 overs.\",\n",
    "        \"Babar Azam top-scored with 58 runs.\",\n",
    "        \"Mohammad Rizwan added a crucial 42-run partnership.\",\n",
    "        \"South Africa dropped two catches during crucial phases.\",\n",
    "        \"Pakistan broke their 3-match losing streak.\",\n",
    "        \"The match was played in Cape Town.\",\n",
    "        \"South Africa remain second on the points table.\"\n",
    "    ],\n",
    "    \"ranking\": [1, 2, 3, 5, 4, 6, 7, 9, 8, 11, 10]\n",
    "},\n",
    "\n",
    "{\n",
    "    \"candidates\": [\n",
    "        \"Manchester City beat Liverpool 3-2 in a thrilling encounter.\",\n",
    "        \"Erling Haaland scored twice and assisted once.\",\n",
    "        \"Kevin De Bruyne orchestrated play with 3 key passes.\",\n",
    "        \"Mohamed Salah netted Liverpool's second goal.\",\n",
    "        \"Phil Foden opened the scoring in the 12th minute.\",\n",
    "        \"Virgil van Dijk was solid in defense despite the loss.\",\n",
    "        \"Alisson made 5 important saves for Liverpool.\",\n",
    "        \"Pep Guardiola praised his team's composure.\",\n",
    "        \"Jurgen Klopp admitted they were second-best today.\",\n",
    "        \"Manchester City move to second place in the standings.\",\n",
    "        \"The match was held at the Etihad Stadium.\"\n",
    "    ],\n",
    "    \"ranking\": [1, 2, 3, 5, 4, 8, 7, 6, 9, 10, 11]\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "524f4a5f-810b-46ea-9490-a78c2ce0fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === NDCG@k Functions ===\n",
    "def dcg_at_k(rel_scores, k):\n",
    "    return sum((2**rel - 1) / np.log2(idx + 2) for idx, rel in enumerate(rel_scores[:k]))\n",
    "\n",
    "def ndcg_at_k(pred_indices, gold_ranks, k):\n",
    "    # Convert gold ranks (lower is better) to relevance scores (higher is better)\n",
    "    # The maximum relevance score should be based on the number of candidates\n",
    "    # The rank 1 item gets the highest relevance, rank N gets the lowest.\n",
    "    # We are using 1-based ranks, so max_rel_val = N, and rank_i gives rel_score = N - (rank_i - 1)\n",
    "    max_rel_val = len(gold_ranks)\n",
    "    rel_scores_map = {idx: max_rel_val - (rank - 1) for idx, rank in enumerate(gold_ranks)}\n",
    "\n",
    "    pred_rels = [rel_scores_map.get(i, 0) for i in pred_indices]\n",
    "\n",
    "    # Ideal relevance scores: sort the actual relevance values present in the gold_ranks\n",
    "    ideal_rels = sorted(rel_scores_map.values(), reverse=True)\n",
    "\n",
    "    dcg = dcg_at_k(pred_rels, k)\n",
    "    idcg = dcg_at_k(ideal_rels, k)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def recall_at_k(pred_indices, gold_top_k_indices, k):\n",
    "    top_k_preds = set(pred_indices[:k])\n",
    "    # Ensure k is not zero to avoid division by zero\n",
    "    if k == 0:\n",
    "        return 0.0\n",
    "    return len(top_k_preds.intersection(set(gold_top_k_indices))) / k\n",
    "\n",
    "def log_metrics(store:list, ndcg2:float, ndcg5:float, ndcg10:float,\n",
    "                rec2:float, rec5:float, rec10:float)->None:\n",
    "    \"\"\"Append one run’s six metrics to `store`.\"\"\"\n",
    "    store.append({\n",
    "        \"ndcg2\": ndcg2, \"ndcg5\": ndcg5, \"ndcg10\": ndcg10,\n",
    "        \"rec2\": rec2,    \"rec5\": rec5,    \"rec10\": rec10\n",
    "    })\n",
    "\n",
    "def top_k(store:list, k:int=5, sort_key:str=\"ndcg5\")->list:\n",
    "    \"\"\"Return the k best runs sorted by the desired key (desc).\"\"\"\n",
    "    return sorted(store, key=lambda d: d[sort_key], reverse=True)[:k]\n",
    "\n",
    "def avg_metrics(runs:list)->dict:\n",
    "    \"\"\"Average every metric across the given runs.\"\"\"\n",
    "    if not runs:\n",
    "        return {} # Return empty dict if no runs to average\n",
    "    keys = runs[0].keys()\n",
    "    return {k: sum(r[k] for r in runs)/len(runs) for k in keys}\n",
    "\n",
    "def report_top3(store:list)->None:\n",
    "    \"\"\"Print top-5 runs (by ndcg5) plus their average block in specified Markdown format.\"\"\"\n",
    "    top3 = top_k(store, 5, \"ndcg5\")\n",
    "\n",
    "    # Top 3 Samples Table\n",
    "    print(\"\\n---\")\n",
    "    print(\"### Top 5 Samples (Sorted by NDCG@5)\")\n",
    "    print(\"---\")\n",
    "    print(\"| Rank | NDCG@2    | NDCG@5    | NDCG@10   | Recall@2  | Recall@5  | Recall@10 |\")\n",
    "    print(\"|------|-----------|-----------|-----------|-----------|-----------|-----------|\")\n",
    "    for i, r in enumerate(top3, 1):\n",
    "        print(f\"| #{i:<4} | {r['ndcg2']:.4f}    | {r['ndcg5']:.4f}    | {r['ndcg10']:.4f}    | {r['rec2']:.4f}    | {r['rec5']:.4f}    | {r['rec10']:.4f}    |\")\n",
    "\n",
    "    # Averaged Metrics Table\n",
    "    mean = avg_metrics(top3)\n",
    "    print(\"\\n---\")\n",
    "    print(\"### Averaged Metrics Over Top 5 Samples\")\n",
    "    print(\"---\")\n",
    "    print(\"| Metric    | Average Value |\")\n",
    "    print(\"|-----------|---------------|\")\n",
    "    for k in mean:\n",
    "        # Align keys for consistent formatting\n",
    "        print(f\"| {k.replace('ndcg', 'NDCG@').replace('rec', 'Recall@'):<9} | {mean[k]:<13.4f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "847ee6ea-2cef-4fce-8937-fa5c386edff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "### Top 5 Samples (Sorted by NDCG@5)\n",
      "---\n",
      "| Rank | NDCG@2    | NDCG@5    | NDCG@10   | Recall@2  | Recall@5  | Recall@10 |\n",
      "|------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "| #1    | 1.0000    | 0.9982    | 0.9980    | 1.0000    | 1.0000    | 0.9000    |\n",
      "| #2    | 1.0000    | 0.9982    | 0.9976    | 1.0000    | 1.0000    | 1.0000    |\n",
      "| #3    | 0.8800    | 0.9379    | 0.9712    | 0.5000    | 0.6000    | 1.0000    |\n",
      "| #4    | 1.0000    | 0.9128    | 0.9741    | 1.0000    | 0.6000    | 0.9000    |\n",
      "| #5    | 0.4099    | 0.6937    | 0.7730    | 0.5000    | 0.6000    | 1.0000    |\n",
      "\n",
      "---\n",
      "### Averaged Metrics Over Top 5 Samples\n",
      "---\n",
      "| Metric    | Average Value |\n",
      "|-----------|---------------|\n",
      "| NDCG@2    | 0.8580        |\n",
      "| NDCG@5    | 0.9082        |\n",
      "| NDCG@10   | 0.9428        |\n",
      "| Recall@2  | 0.8000        |\n",
      "| Recall@5  | 0.7600        |\n",
      "| Recall@10 | 0.9600        |\n"
     ]
    }
   ],
   "source": [
    "# === Inference + Evaluation ===\n",
    "metrics_log = []\n",
    "\n",
    "for idx, sample in enumerate(data_points):\n",
    "    sentences = sample[\"candidates\"]\n",
    "    gold_ranks = sample[\"ranking\"] # This is list of 1-based ranks, where gold_ranks[i] is rank of sentence i\n",
    "    n_sentences = len(sentences)\n",
    "\n",
    "    # Calculate gold_top_k_indices for recall: 0-based indices of truly top-ranked items\n",
    "    indexed_gold_ranks = list(enumerate(gold_ranks)) # [(0, rank0), (1, rank1), ...]\n",
    "    sorted_gold_pairs_by_rank = sorted(indexed_gold_ranks, key=lambda x: x[1]) # Sort by rank\n",
    "    gold_original_indices_sorted_by_rank = [pair[0] for pair in sorted_gold_pairs_by_rank] # Extract original 0-based indices\n",
    "\n",
    "    # Ensure k does not exceed the number of available candidates for slicing\n",
    "    gold_top_k_indices_rec2 = gold_original_indices_sorted_by_rank[:min(2, n_sentences)]\n",
    "    gold_top_k_indices_rec5 = gold_original_indices_sorted_by_rank[:min(5, n_sentences)]\n",
    "    gold_top_k_indices_rec10 = gold_original_indices_sorted_by_rank[:min(10, n_sentences)]\n",
    "\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an AI that ranks sports-related sentences based on importance using these criteria:\\n\"\n",
    "        \"1. Sports Relevance\\n\"\n",
    "        \"2. Emotional Intensity\\n\"\n",
    "        \"3. Sarcasm Presence\\n\"\n",
    "        \"4. Key People Mentions\\n\"\n",
    "        \"5. Buzzword Usage\\n\\n\"\n",
    "        f\"Rank the following {n_sentences} sentences (0-based indices). Output ONLY numbers in order (best first), separated by spaces:\\n\\n\"\n",
    "        + \"\\n\".join(f\"{i}. {s}\" for i, s in enumerate(sentences)) +\n",
    "        \"\\n\\nRanked indices:\"\n",
    "    )\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        [prompt],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=4096\n",
    "    )\n",
    "    input_ids = tokenized[\"input_ids\"].to(device)\n",
    "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
    "    input_length = input_ids.shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=min(100, 15 * n_sentences), # Generate enough tokens for ranking\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            num_beams=1,\n",
    "            temperature=0.8\n",
    "        )\n",
    "\n",
    "    generated_ids = output[:, input_length:]\n",
    "    response_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Robust parsing of generated indices\n",
    "    resp_clean = re.sub(r'[^0-9 ]', '', response_text) # Remove non-numeric, non-space characters\n",
    "    numbers = re.findall(r'\\b\\d+\\b', resp_clean) # Find all sequences of digits as whole numbers\n",
    "    indices = []\n",
    "    for n_str in numbers:\n",
    "        try:\n",
    "            idx_n = int(n_str)\n",
    "            if 0 <= idx_n < n_sentences and idx_n not in indices:\n",
    "                indices.append(idx_n)\n",
    "        except ValueError:\n",
    "            pass # Should not happen with re.sub and re.findall as above, but good practice\n",
    "\n",
    "    # If the model didn't generate all n_sentences indices, append missing ones\n",
    "    if len(indices) < n_sentences:\n",
    "        missing = [i for i in range(n_sentences) if i not in indices]\n",
    "        indices.extend(missing[:n_sentences - len(indices)]) # Only add enough to reach n_sentences, if needed\n",
    "\n",
    "    # Compute reward using NDCG@k\n",
    "    ndcg2 = ndcg_at_k(indices, gold_ranks, k=2)\n",
    "    ndcg5 = ndcg_at_k(indices, gold_ranks, k=5)\n",
    "    ndcg10 = ndcg_at_k(indices, gold_ranks, k=10)\n",
    "\n",
    "    # Use the correctly derived gold_top_k_indices for each k\n",
    "    rec2 = recall_at_k(indices, gold_top_k_indices_rec2, k=2)\n",
    "    rec5 = recall_at_k(indices, gold_top_k_indices_rec5, k=5)\n",
    "    rec10 = recall_at_k(indices, gold_top_k_indices_rec10, k=10)\n",
    "\n",
    "    log_metrics(metrics_log, ndcg2, ndcg5, ndcg10, rec2,  rec5,  rec10)\n",
    "    # print(\"Metrics we got for current sample\",metrics_log[-1]) # Commented out for cleaner final output\n",
    "\n",
    "# === Generate final report ===\n",
    "report_top3(metrics_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed8343dc-65dd-40ff-a171-c1f4409913f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nitishk_iitp/miniconda3/lib/python3.13/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "### Top 5 Samples (Sorted by NDCG@5)\n",
      "---\n",
      "| Rank | NDCG@2    | NDCG@5    | NDCG@10   | Recall@2  | Recall@5  | Recall@10 |\n",
      "|------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "| #1    | 1.0000    | 0.9982    | 0.9980    | 1.0000    | 1.0000    | 0.9000    |\n",
      "| #2    | 1.0000    | 0.9982    | 0.9976    | 1.0000    | 1.0000    | 1.0000    |\n",
      "| #3    | 0.8800    | 0.9379    | 0.9712    | 0.5000    | 0.6000    | 1.0000    |\n",
      "| #4    | 1.0000    | 0.9128    | 0.9741    | 1.0000    | 0.6000    | 0.9000    |\n",
      "| #5    | 0.4099    | 0.6937    | 0.7730    | 0.5000    | 0.6000    | 1.0000    |\n",
      "\n",
      "---\n",
      "### Averaged Metrics Over Top 5 Samples\n",
      "---\n",
      "| Metric    | Average Value |\n",
      "|-----------|---------------|\n",
      "| NDCG@2    | 0.8580        |\n",
      "| NDCG@5    | 0.9082        |\n",
      "| NDCG@10   | 0.9428        |\n",
      "| Recall@2  | 0.8000        |\n",
      "| Recall@5  | 0.7600        |\n",
      "| Recall@10 | 0.9600        |\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import re\n",
    "\n",
    "# === Inference Function using TRL-style prompting ===\n",
    "def generate_ranking(model, tokenizer, sentences, device=\"cuda\"):\n",
    "    n_sentences = len(sentences)\n",
    "\n",
    "    # Format prompt as instruction\n",
    "    prompt = (\n",
    "        \"You are an AI that ranks sports-related sentences based on importance using these criteria:\\n\"\n",
    "        \"1. Sports Relevance\\n\"\n",
    "        \"2. Emotional Intensity\\n\"\n",
    "        \"3. Sarcasm Presence\\n\"\n",
    "        \"4. Key People Mentions\\n\"\n",
    "        \"5. Buzzword Usage\\n\\n\"\n",
    "        f\"Rank the following {n_sentences} sentences (0-based indices). Output ONLY numbers in order (best first), separated by spaces:\\n\\n\"\n",
    "        + \"\\n\".join(f\"{i}. {s}\" for i, s in enumerate(sentences)) +\n",
    "        \"\\n\\nRanked indices:\"\n",
    "    )\n",
    "\n",
    "    # Apply chat template if model is instruction/chat-tuned\n",
    "    if tokenizer.chat_template is not None:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\", padding=True, truncation=True, max_length=4096)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=min(100, 15 * n_sentences),\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=False,  # Try greedy decoding if SFT used it\n",
    "            temperature=0.7,\n",
    "            top_p=None\n",
    "        )\n",
    "\n",
    "    input_length = inputs[\"input_ids\"].shape[1]\n",
    "    generated = outputs[0][input_length:]\n",
    "    response_text = tokenizer.decode(generated, skip_special_tokens=True)\n",
    "\n",
    "    # Parse response\n",
    "    numbers = re.findall(r'\\b\\d+\\b', response_text)\n",
    "    indices = []\n",
    "    for n_str in numbers:\n",
    "        try:\n",
    "            idx_n = int(n_str)\n",
    "            if 0 <= idx_n < n_sentences and idx_n not in indices:\n",
    "                indices.append(idx_n)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # Fill missing indices if needed\n",
    "    if len(indices) < n_sentences:\n",
    "        missing = [i for i in range(n_sentences) if i not in indices]\n",
    "        indices.extend(missing[:n_sentences - len(indices)])\n",
    "\n",
    "    return indices\n",
    "\n",
    "metrics_log = []\n",
    "\n",
    "for idx, sample in enumerate(data_points):\n",
    "    sentences = sample[\"candidates\"]\n",
    "    gold_ranks = sample[\"ranking\"]  # 1-based ranks\n",
    "    n_sentences = len(sentences)\n",
    "\n",
    "    # Derive gold top-k indices as before\n",
    "    indexed_gold_ranks = list(enumerate(gold_ranks))\n",
    "    sorted_gold_pairs_by_rank = sorted(indexed_gold_ranks, key=lambda x: x[1])\n",
    "    gold_original_indices_sorted_by_rank = [pair[0] for pair in sorted_gold_pairs_by_rank]\n",
    "\n",
    "    gold_top_k_indices_rec2 = gold_original_indices_sorted_by_rank[:min(2, n_sentences)]\n",
    "    gold_top_k_indices_rec5 = gold_original_indices_sorted_by_rank[:min(5, n_sentences)]\n",
    "    gold_top_k_indices_rec10 = gold_original_indices_sorted_by_rank[:min(10, n_sentences)]\n",
    "\n",
    "    # Generate ranking with TRL-style inference\n",
    "    predicted_indices = generate_ranking(model, tokenizer, sentences, device=device)\n",
    "\n",
    "    # Evaluate\n",
    "    ndcg2 = ndcg_at_k(predicted_indices, gold_ranks, k=2)\n",
    "    ndcg5 = ndcg_at_k(predicted_indices, gold_ranks, k=5)\n",
    "    ndcg10 = ndcg_at_k(predicted_indices, gold_ranks, k=10)\n",
    "\n",
    "    rec2 = recall_at_k(predicted_indices, gold_top_k_indices_rec2, k=2)\n",
    "    rec5 = recall_at_k(predicted_indices, gold_top_k_indices_rec5, k=5)\n",
    "    rec10 = recall_at_k(predicted_indices, gold_top_k_indices_rec10, k=10)\n",
    "\n",
    "    log_metrics(metrics_log, ndcg2, ndcg5, ndcg10, rec2, rec5, rec10)\n",
    "\n",
    "# Final report\n",
    "report_top3(metrics_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad6b93-3d22-4fe1-a412-7bde98174e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd41636-081d-47a9-bb51-8e7bb3043c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb02776c-93b6-481e-bf3d-cd549c92b706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nitishk_iitp/miniconda3/lib/python3.13/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "### Top 5 Samples (Sorted by NDCG@5)\n",
      "---\n",
      "| Rank | NDCG@2    | NDCG@5    | NDCG@10   | Recall@2  | Recall@5  | Recall@10 |\n",
      "|------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "| #1    | 0.8200    | 0.8403    | 0.9019    | 0.5000    | 0.6000    | 0.9000    |\n",
      "| #2    | 0.7900    | 0.8232    | 0.8915    | 0.5000    | 0.6000    | 0.9000    |\n",
      "| #3    | 0.7900    | 0.6957    | 0.8699    | 0.5000    | 0.4000    | 1.0000    |\n",
      "| #4    | 0.7750    | 0.6890    | 0.8799    | 0.5000    | 0.4000    | 1.0000    |\n",
      "| #5    | 0.5271    | 0.4937    | 0.6550    | 0.5000    | 0.6000    | 0.7000    |\n",
      "\n",
      "---\n",
      "### Averaged Metrics Over Top 5 Samples\n",
      "---\n",
      "| Metric    | Average Value |\n",
      "|-----------|---------------|\n",
      "| NDCG@2    | 0.7405        |\n",
      "| NDCG@5    | 0.7084        |\n",
      "| NDCG@10   | 0.8396        |\n",
      "| Recall@2  | 0.5000        |\n",
      "| Recall@5  | 0.5200        |\n",
      "| Recall@10 | 0.9000        |\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import re\n",
    "\n",
    "\n",
    "# === Inference Function using TRL-style prompting ===\n",
    "def generate_ranking(model, tokenizer, sentences, device=\"cuda\"):\n",
    "    n_sentences = len(sentences)\n",
    "\n",
    "    # Format prompt as instruction\n",
    "    prompt = (\n",
    "        \"You are an AI that ranks sports-related sentences based on importance using these criteria:\\n\"\n",
    "        \"1. Sports Relevance\\n\"\n",
    "        \"2. Emotional Intensity\\n\"\n",
    "        \"3. Sarcasm Presence\\n\"\n",
    "        \"4. Key People Mentions\\n\"\n",
    "        \"5. Buzzword Usage\\n\\n\"\n",
    "        f\"Rank the following {n_sentences} sentences (0-based indices). Output ONLY numbers in order (best first), separated by spaces:\\n\\n\"\n",
    "        + \"\\n\".join(f\"{i}. {s}\" for i, s in enumerate(sentences)) +\n",
    "        \"\\n\\nRanked indices:\"\n",
    "    )\n",
    "\n",
    "    # Apply chat template if model is instruction/chat-tuned\n",
    "    if tokenizer.chat_template is not None:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\", padding=True, truncation=True, max_length=4096)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=min(100, 15 * n_sentences),\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=False,  # Try greedy decoding if SFT used it\n",
    "            temperature=0.1,\n",
    "            top_p=None\n",
    "        )\n",
    "\n",
    "    input_length = inputs[\"input_ids\"].shape[1]\n",
    "    generated = outputs[0][input_length:]\n",
    "    response_text = tokenizer.decode(generated, skip_special_tokens=True)\n",
    "\n",
    "    # Parse response\n",
    "    numbers = re.findall(r'\\b\\d+\\b', response_text)\n",
    "    indices = []\n",
    "    for n_str in numbers:\n",
    "        try:\n",
    "            idx_n = int(n_str)\n",
    "            if 0 <= idx_n < n_sentences and idx_n not in indices:\n",
    "                indices.append(idx_n)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # Fill missing indices if needed\n",
    "    if len(indices) < n_sentences:\n",
    "        missing = [i for i in range(n_sentences) if i not in indices]\n",
    "        indices.extend(missing[:n_sentences - len(indices)])\n",
    "\n",
    "    return indices\n",
    "\n",
    "metrics_log = []\n",
    "\n",
    "for idx, sample in enumerate(data_points):\n",
    "    sentences = sample[\"candidates\"]\n",
    "    gold_ranks = sample[\"ranking\"]  # 1-based ranks\n",
    "    n_sentences = len(sentences)\n",
    "\n",
    "    # Derive gold top-k indices as before\n",
    "    indexed_gold_ranks = list(enumerate(gold_ranks))\n",
    "    sorted_gold_pairs_by_rank = sorted(indexed_gold_ranks, key=lambda x: x[1])\n",
    "    gold_original_indices_sorted_by_rank = [pair[0] for pair in sorted_gold_pairs_by_rank]\n",
    "\n",
    "    gold_top_k_indices_rec2 = gold_original_indices_sorted_by_rank[:min(2, n_sentences)]\n",
    "    gold_top_k_indices_rec5 = gold_original_indices_sorted_by_rank[:min(5, n_sentences)]\n",
    "    gold_top_k_indices_rec10 = gold_original_indices_sorted_by_rank[:min(10, n_sentences)]\n",
    "\n",
    "    # Generate ranking with TRL-style inference\n",
    "    predicted_indices = generate_ranking(model, tokenizer, sentences, device=device)\n",
    "\n",
    "    # Evaluate\n",
    "    ndcg2 = ndcg_at_k(predicted_indices, gold_ranks, k=2)\n",
    "    ndcg5 = ndcg_at_k(predicted_indices, gold_ranks, k=5)\n",
    "    ndcg10 = ndcg_at_k(predicted_indices, gold_ranks, k=10)\n",
    "\n",
    "    rec2 = recall_at_k(predicted_indices, gold_top_k_indices_rec2, k=2)\n",
    "    rec5 = recall_at_k(predicted_indices, gold_top_k_indices_rec5, k=5)\n",
    "    rec10 = recall_at_k(predicted_indices, gold_top_k_indices_rec10, k=10)\n",
    "\n",
    "    log_metrics(metrics_log, ndcg2, ndcg5, ndcg10, rec2, rec5, rec10)\n",
    "\n",
    "# Final report\n",
    "report_top3(metrics_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b9096-8773-4c25-8d4c-d97bbd25cccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
